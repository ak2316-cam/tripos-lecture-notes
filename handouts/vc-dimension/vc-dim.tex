\documentclass[a4paper]{amsart}
\usepackage[nokoma, noindent,fancytheorems]{adam}
\usepackage{tikz-cd}


% NOTE: for a more compact, black and white style for printing, use
% the below.

% \documentclass[a3paper, 10pt]{amsart}

% \usepackage[nokoma, noindent]{adam}
% \usepackage[landscape,margin=0.5in]{geometry}
% \usepackage{tikz-cd}
% \usepackage{multicol}

% \setlist[enumerate]{leftmargin=8mm}
% \setlist[itemize]{leftmargin=8mm}

% \newcommand{\enumpre}{}
% % \newcommand{\enumpre}{\vspace{-1.5\baselineskip}}
% \renewcommand{\vocab}[1]{\emph{#1}}

\title{VC Dimension}
\author{Mathematical Tripos Part II}
\date{\today}

\begin{document}
% \begin{multicols*}{5}
\maketitle

% \section{Background}

% We will take $h$ to be a \vocab{hypothesis function} (used to predict $Y$ from $X$). $L$ will be a \vocab{loss function} (which measures how well the hypothesis function performs). 
% We will work in a classification setting where $Y = \{-1, 1\}$ for example, in particular it's discrete (and not continuous like regression).


% In a classification setting, our loss function is
% $$
% L(h(x), y) = \begin{cases}
% 0 & \text{if } h(x) = y, \\
% 1 & \text{otherwise}.
% \end{cases}
% $$
% We want to minimize the expected \vocab{risk}, $R(h) = \EE[L(h)]$ which is our expected loss.

% We have the bound
% $$
% \EE[R(\hat{h})] - R(h^*) \leq 2 \mathcal{R}_n(F),
% $$
% where $h^*$ is the optimal function which minimizes risk.

% We also have
% $$
% \mathcal{R}(F(z_1: m)) \leq \sqrt{2 \log (H(x_1: n))/n},
% $$
% where $H(x_1: n) = \{h(x_1), h(x_2), \dots, h(x_n)\}$.
% We won't worry about what the undefined terms mean.

% \section{VC Dimension}



% Let $H$ be the class of functions $h: X \rightarrow \{a, b\}$ with $a \neq b$ (usually $a = -1, b = +1$) with $|H| \geq 2$. 

% \begin{definition}[Shatter]
%     We say that $H$ \vocab{shatters}
%     $x_{1:n} \in X^n$ if $|H(x_{1:n})| = 2^n$. 
% \end{definition}

% \begin{definition}[Shattering Coefficient]
% Let $s(H, n) = \max_{x_{1:n}} |H(x_{1:n})|$, which is the \vocab{shattering coefficient}.
% \end{definition}

% \begin{definition}[VC-Dimension]
%     We say $\operatorname{VC}(H)$, the \vocab{VC dimension}, is the largest $n$ such that some $x_{1:n}$ is shattered, or say it's the max $n$ such that $s(H, n) = 2^n$.
% \end{definition}

% We want to be able to shatter some points because our function class can classify in all possible ways, but we don't want $\opereratorname{VC}(H)$ to be too large because it makes our function class too complicated and can overfit. Also our error is bounded by.

% The VC dimension of a set of functions is a measure of its ability to overfit the training data. A high VC dimension indicates that the set of functions is likely to overfit the training data, while a low VC dimension indicates that the set of functions is less likely to overfit the training data.

% We are going to consider the task of classifying a set $X$ into labels in $Y = \{-1, 1\}$. Such a classification is done with a `hypothesis' function $h: X \rightarrow Y$. The class of all hypothesis functions under consideration we will take to be $\mathcal{H}$.

% \begin{definition}[Shattering]
%     A set $S$ is said to be \vocab{shattered} by $\mathcal{H}$ if for any possible labelling of the points in $S$, there exists a function $h \in \mathcal{H}$ that correctly classifies all of the points in $S$.
% \end{definition}

% \begin{definition}[VC Dimension]
%     The \vocab{VC dimension} of a class of functions $\mathcal{H}$ is $\operatorname{VC}(\mathcal{H}) = \max \{|S| \mid S \subseteq X \text{ and } \mathcal{H} \text{ can shatter } S\}$.
% \end{definition}

% \begin{definition}[Shattering Coefficient]
%     The \vocab{shattering coefficient} $S(H, n)$ is $\max|\{S \subseteq \{1, \dots, n\} \mid 

% \end{definition}


\section{Setup}

We work in a classification setting. We have a set $\mathcal{X}$ and want to classify them into labels $\{-1, 1\}$. We do this through a \vocab{hypothesis} function $h: \mathcal{X} \rightarrow \{-1, 1\}$.

For a given clasification $h(x)$, we define the \vocab{loss} as $\ell(h(x), y)= \ii[h(x) \neq y]$, where $y$ the the correct label for $x$. We define the \vocab{risk} of a hypothesis to be it's expected loss, $R(h) = \EE[\ell(H(X), Y)]$.

\section{VC Dimension}

The VC dimension of a set of hypothesis functions is a measure of its ability to overfit the training data. A high VC dimension indicates that the set of functions is likely to overfit the training data, while a low VC dimension indicates that the set of functions is less likely to overfit the training data.


Consider $\{x_1, \dots, x_n \} \in \mathcal{X}$.
Given a collection of possible hypothesis $\mathcal{H}$, we can count how many different ways we can partition the $x_i$ (into the two labels $\pm 1$). We define\footnote{Informally, $\mathcal{H}(x_1, \dots, x_n)$ is the set of `obtainable paritions' of $\{x_1, \dots, x_n\}$ using a hypothesis in $\mathcal{H}$. Also we just suppose $h(x_i) = 1$, but we could take $h(x_i) = -1$.}
$$
\mathcal{H}(x_1, \dots, x_n) = \{S \subseteq \{x_1, \dots, x_n \} \mid \exists h \in \mathcal{H} \text{ where } h(x_i) = 1\; \forall x_i \in S\}.
$$
We usually just care about the size of this set, and we note that we trivially have $|\mathcal{H}(x_1, \dots, x_n)|$ $\leq 2^n$.


\begin{definition*}[Shattered]
    We say that $\{x_1, \dots, x_n\}$ is \vocab{shattered} by $\mathcal{H}$ if $|\mathcal{H}(x_1, \dots, x_n)|$ $= 2^n$. 
\end{definition*}

That is, if for any possible labelling of the points in $\{x_1, \dots, x_n\}$, there exists a hypothesis $h \in \mathcal{H}$ that correctly classifies all of the points in $S$.


\begin{definition*}[VC Dimension]
    The \vocab{VC dimension} $\operatorname{VC}(\mathcal{H})$ is the largest integer $n$ such that some $\{x_1$, $\dots$, $x_n\}$ is shattered by $\mathcal{H}$, or $\infty$ if none exists.
\end{definition*}

\begin{definition*}[Shattering Coefficient]
    We define the \vocab{shattering cofficient} $s(\mathcal{H}, n)$ to be
    $$
    s(\mathcal{H}, n) = \max_{S \subset \mathcal{X}, |S| = n} |\mathcal{H}(S)|.
    $$
\end{definition*}


So equivalently, $\operatorname{VC}(\mathcal{H}) = \sup\{ n \in \N \mid s(\mathcal{H}, n) = 2^n\}$.

To show that $\operatorname{VC}(\mathcal{H}) = n$, we must first find an $\{x_1, \dots, x_n\}$ that is shattered (this is usually easy), and show that no $\{x_1, \dots, x_{n + 1}\}$ can be shattered (this is usually harder).

\begin{example}[Finding VC Dimension]
Consider the example of $\mathcal{X} = \R$, and the set of hypothesis functions classify points based on whether or not they are in a given interval:
$$
\mathcal{H} = \{h_{a, b} \mid h_{a, b}(x) = \ii_{[a, b)}(x), \; a, b \in \R\}.
$$

Consider $n$ distinct points $x_1 < x_2 < \dots < x_n$. These divide up the real line into $n + 1$ intervals $(-\infty, x_1], (x_1, x_2], \dots, (x_{n - 1}, x_n], (x_n, \infty)$. 

If $a$ and $a'$ are in the same interval, and $b$ and $b'$ are in the same interval, then $h_{a, b}(x_i) = h_{a', b'}(x_i)$ for all $i$. Thus every possible behaviour of $h_{a, b}$ on the $x_i$ is obtained by picking one of the $n + 1$ intervals for each of $a$ and $b$. Thus
$$
s(\mathcal{H}, n) \leq (n + 1)^2.
$$

Now we compute the VC dimension. Clearly any $\{x_1, x_2\}$ can be shattered, but with three points $\{x_1, x_2, x_3\}$ with $x_1 < x_2 < x_3$, we can never have $h(x_1) = h(x_3) = 1$ and $h(x_2) = 0$, and so $\operatorname{VC}(\mathcal{H}) = 2$.
\end{example}

\begin{example}[VC Dimension for Vector Spaces]
    Consider a vector space $\mathcal{F}$ of functions $f: \mathcal{X} \rightarrow \R$, and from this form the class of hypotheses
    $$
    \mathcal{H} = \{h_f \mid f \in \mathcal{F}, \; h_f(x) = \operatorname{sgn}(f(x)) \},
    $$
    where we take $\operatorname{sgn}(0) = -1$.

    We will prove that $\operatorname{VC}(\mathcal{H}) \leq \dim(\mathcal{F})$.

    Let $d = \dim \mathcal{F} + 1$, and let $\{x_1, \dots, x_d\} \subset \mathcal{X}$. We need to show that this cannot be shattered by $\mathcal{H}$. Consider the linear map $L: \mathcal{F} \rightarrow \R^d$ given by
    $$
L(f) = (f(x_1), \dots, f(x_d)) \in \R^d.
    $$
    The rank of $L$ is at most $\dim \mathcal{F} = d - 1 < d$, therefore there must exist non-zero $\gamma \in \R^d$ orthogonal to everything in the image of $L(\mathcal{F})$, that is,
    $$
    \sum_{i, \gamma_i >0} \gamma_i f(x_i) + \sum_{i, \gamma_i \leq 0} \gamma_i f(x_i) = 0 \quad \text{for all }f \in \mathcal{F},
    $$
    where (WLOG) at least one component of $\gamma$ is strictly positive. Let $I_+ = \{i \mid \gamma_i >0\}$ and $I_- = \{i \mid \gamma_i \leq 0\}$. Then it is not possible to have
    \begin{align*}
        h(x_i) = 1 &\implies f(x_i) > 0 \text{ for all }i \in I_+,\\
        h(x_i) = -1 &\implies f(x_i) \leq 0 \text{ for all }i \in I_-,
    \end{align*}
    as otherwise the LHS of our orthogonality equation would be strictly positive. Thus $\{x_1, \dots, x_d\}$ cannot be shattered, and $\operatorname{VC}(\mathcal{H}) \leq d - 1$, as required.
\end{example}


\section{Sauer-Shelah Lemma}

Note in our first example we had $s(\mathcal{H}, n) \leq (n + 1)^{\operatorname{VC}(\mathcal{H})}$. This result holds more genererally.

\begin{lemma*}[Sauer-Shelah]
    Let $\mathcal{H}$ have finite VC dimension $d$. Then
    $$
s(\mathcal{H}, n) \leq (n + 1)^d.
    $$
\end{lemma*}
\begin{proof}
    Non-examinable.
\end{proof}



% \end{multicols*}
\end{document}
